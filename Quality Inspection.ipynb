{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b77f1ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'pip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "!pip install Pillow\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def read_images_from_folder(folder_path):\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(('.png', '.JPG', '.jpeg', '.bmp', '.gif')):\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "            image = Image.open(image_path)\n",
    "            yield image, filename\n",
    "\n",
    "def crop_and_save_images(input_folder, output_folder, crop_box):\n",
    "    \n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    for image, filename in read_images_from_folder(input_folder):\n",
    "        # print(f\"Processing image: {filename}\")\n",
    "        # Crop the image\n",
    "        cropped_image = image.crop(crop_box)\n",
    "        # Construct the output path\n",
    "        output_path = os.path.join(output_folder, filename)\n",
    "        # Save the cropped image\n",
    "        cropped_image.save(output_path)\n",
    "        # print(f\"Saved cropped image: {output_path}\")\n",
    "\n",
    "# Construct the relative path to the input folder\n",
    "input_folder = \"Superviseddata\"\n",
    "output_folder = \"CroppedImages\"\n",
    "crop_box = (1840,1180,2200,1845)\n",
    "crop_and_save_images(input_folder, output_folder, crop_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f4aa290b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'pip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'pip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'pip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mrandom\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpickle\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n",
    "!pip install opencv-python\n",
    "!pip install opencv-python-headless\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c93b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRECTORY = r'Superviseddata'\n",
    "CATEGORIES= ['/Good' , '/Bad']\n",
    "IMG_SIZE=100\n",
    "data=[]\n",
    "x=[]\n",
    "y=[]\n",
    "\n",
    "for category in CATEGORIES:\n",
    "    folder= DIRECTORY+category\n",
    "    label= CATEGORIES.index(category)\n",
    "    for img in os.listdir(folder):\n",
    "        img_path=folder+'/'+img\n",
    "        img_arr=cv2.imread(img_path)\n",
    "        img_arr=cv2.resize(img_arr,(100,100))\n",
    "        data.append([img_arr, label])\n",
    "\n",
    "random.shuffle(data)\n",
    "for features, labels in data:\n",
    "    x.append(features)\n",
    "    y.append(labels)\n",
    "x=np.array(x)\n",
    "y=np.array(y)\n",
    "pickle.dump(x, open('x.pkl','wb'))\n",
    "pickle.dump(y, open('y.pkl','wb'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbe75aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y)\n",
    "fig, ax = plt.subplots(ncols = 2, figsize=(10, 5))\n",
    "ax[0].imshow(x[0])\n",
    "ax[1].imshow(x[2])\n",
    "# 0 is good and 1 is bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e25327",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.models import Sequential\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8325bbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale data\n",
    "x = x/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b096f32",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "!pip install --upgrade pip setuptools wheel\n",
    "!pip install scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "x = np.array([[1], [2], [3], [4]])\n",
    "y = np.array([0, 1, 0, 1])\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c9dafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train and evaluate using KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score \n",
    "knn=KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(x_train.reshape(len(x_train),-1),y_train)\n",
    "y_pred_knn=knn.predict(x_test.reshape(len(x_test),-1))\n",
    "print(confusion_matrix(y_test,y_pred_knn))\n",
    "print(classification_report(y_test,y_pred_knn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed18e88-9bc2-464b-80e9-e8b061203602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import required libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# 2. Make sure x and y are already defined (e.g., image data and labels)\n",
    "\n",
    "# 3. Split data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 4. Train and evaluate KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(x_train.reshape(len(x_train), -1), y_train)\n",
    "y_pred_knn = knn.predict(x_test.reshape(len(x_test), -1))\n",
    "print(confusion_matrix(y_test, y_pred_knn))\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "# 5. Train and evaluate Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "rf.fit(x_train.reshape(len(x_train), -1), y_train)\n",
    "y_pred_rf = rf.predict(x_test.reshape(len(x_test), -1))\n",
    "print(confusion_matrix(y_test, y_pred_rf))\n",
    "print(classification_report(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c32195",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train and evaluate using random forest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "x = np.array([\n",
    "    [0.1, 0.2],\n",
    "    [0.2, 0.3],\n",
    "    [0.3, 0.4],\n",
    "    [0.4, 0.5],\n",
    "    [0.5, 0.6]\n",
    "])\n",
    "y = np.array([0, 1, 0, 1, 0])\n",
    "\n",
    "# Step 3: Split the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "rf=RandomForestClassifier(n_estimators=100)\n",
    "rf.fit(x_train.reshape(len(x_train), -1), y_train)\n",
    "y_pred_rf=rf.predict(x_test.reshape(len(x_test),-1))\n",
    "print(confusion_matrix(y_test,y_pred_rf))\n",
    "print(classification_report(y_test,y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccb7fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train and evaluate using SVM\n",
    "from sklearn.svm import SVC\n",
    "svm=SVC()\n",
    "svm.fit(x_train.reshape(len(x_train),-1),y_train)\n",
    "y_pred_svm=svm.predict(x_test.reshape(len(x_test),-1))\n",
    "print(confusion_matrix(y_test,y_pred_svm))\n",
    "print(classification_report(y_test,y_pred_svm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf68c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow\n",
    "import time\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "NAME=f'defect-vs-nodefect-prediction-{int(time.time())}'\n",
    "tensorboard=TensorBoard(log_dir=f'logs\\\\{NAME}\\\\')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9892fb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train deep learning model\n",
    "#Deep Learning\n",
    "model= Sequential()\n",
    "model.add(Conv2D(64,(3,3), activation='relu', input_shape=x.shape[1:]))\n",
    "\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "          \n",
    "model.add(Conv2D(64,(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid')) #1 softmax\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.fit(x_train,y_train, epochs=37, batch_size=5, callbacks=[tensorboard])\n",
    "model.evaluate(x_test,y_test) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d8a2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#make predictions\n",
    "i=0\n",
    "data_DL=[]\n",
    "data_DL_O =[]\n",
    "while i<len(y_test):\n",
    "    plt.imshow(x_test[i])\n",
    "    plt.show()\n",
    "\n",
    "    y_pred_DL_O=model.predict(x_test[i,:].reshape(1, 100, 100, 3))\n",
    "    print(y_pred_DL_O)\n",
    "    y_pred_DL=y_pred_DL_O>0.5\n",
    "\n",
    "\n",
    "    if(y_pred_DL==False):\n",
    "        pred='not_defective'\n",
    "    else:\n",
    "        pred='defective'\n",
    "    print(f\"The prediction was: {pred}\")\n",
    "    print(f\"The actual label was: {y_pred_DL}\")\n",
    "    if(y_test[i]==0): #good == 0  \n",
    "        print(f\"The actual label is: not defective\")\n",
    "    else: #bad == 1 \n",
    "        print(f\"The actual label is: defective\")\n",
    "\n",
    "    data_DL.append(int(y_pred_DL))\n",
    "    data_DL_O.append(y_pred_DL_O)\n",
    "    \n",
    "    i=i+1\n",
    "y_DL=[]\n",
    "for n in range(len(y_test)):\n",
    "    y_DL.append(n)\n",
    "\n",
    "#plotting    \n",
    "fig, ax = plt.subplots(ncols = 2, figsize=(10, 5))\n",
    "ax[1].scatter(y_DL,data_DL)\n",
    "# ax[1].axhline(y=0.02)\n",
    "\n",
    "ax[0].scatter(y_DL,data_DL_O)\n",
    "ax[0].axhline(y=0.5)\n",
    "\n",
    "##\n",
    "\n",
    "#confusion matrix\n",
    "cm = confusion_matrix(y_test, (data_DL))\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fe972a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate all models by using confusion matrix\n",
    "def model_evaluation(y_test, y_pred):\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    TP = cm[1][1]\n",
    "    FN = cm[1][0]\n",
    "    FP = cm[0][1]\n",
    "    TN = cm[0][0]\n",
    "    accuracy = (TP + TN) / (TP + FP + FN + TN)\n",
    "    sensitivity = TP / (TP + FN)\n",
    "    specificity = TN / (TN + FP)\n",
    "    precision = TP / (TP + FP)\n",
    "    Negative_Predictive_Value = TN / (TN + FN)\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"Sensitivity: {sensitivity}\")\n",
    "    print(f\"Specificity: {specificity}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Negative Predictive Value: {Negative_Predictive_Value}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1548bf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate KNN\n",
    "model_evaluation(y_test, y_pred_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38df511",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate random forest\n",
    "model_evaluation(y_test, y_pred_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88818850",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evualate SVM\n",
    "model_evaluation(y_test, y_pred_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54be063f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate deep learning\n",
    "model_evaluation(y_test, data_DL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170fc480",
   "metadata": {},
   "source": [
    "## Now Using data augmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a575df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "# Create an instance of the ImageDataGenerator class\n",
    "datagen = ImageDataGenerator(\n",
    "    # rotation_range=10,\n",
    "    # width_shift_range=0.1,\n",
    "    # height_shift_range=0.1,               ## flip is not good for this dataset. Zoom is good\n",
    "    # shear_range=0.1,\n",
    "    # zoom_range=0.2,\n",
    "    # horizontal_flip=True,\n",
    "    # vertical_flip=True,\n",
    "    # brightness_range=[0.4,1.9],\n",
    "    # featurewise_center=True,    # Set input mean to 0\n",
    "    featurewise_std_normalization=True,  #\n",
    "    preprocessing_function=lambda x: x + np.random.normal(0, 0.09, x.shape),\n",
    "    # channel_shift_range=50.0,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "DIRECTORY = r'Superviseddata'\n",
    "CATEGORIES= ['/Good' , '/Bad']\n",
    "IMG_SIZE=100\n",
    "data=[]\n",
    "x=[]\n",
    "y=[]\n",
    "img_arr=[]\n",
    "augmented_images=[]\n",
    "folder=''\n",
    "label=0\n",
    "\n",
    "for category in CATEGORIES:\n",
    "    folder= DIRECTORY+category\n",
    "    label= CATEGORIES.index(category)\n",
    "    for img in os.listdir(folder):\n",
    "        img_path=folder+'/'+img\n",
    "        img_arr=cv2.imread(img_path)\n",
    "        augmented_images = [datagen.random_transform(img_arr) for _ in range(3)]\n",
    "        for aug_img in augmented_images:\n",
    "            aug_img_resized = cv2.resize(aug_img, (IMG_SIZE, IMG_SIZE))\n",
    "            data.append([aug_img_resized, label])\n",
    "\n",
    "\n",
    "random.shuffle(data)\n",
    "for features, labels in data:\n",
    "    x.append(features)\n",
    "    y.append(labels)\n",
    "x=np.array(x)\n",
    "y=np.array(y)\n",
    "pickle.dump(x, open('x.pkl','wb'))\n",
    "pickle.dump(y, open('y.pkl','wb'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4830be06",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8012db",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14009b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa5e198",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train and evaluate using KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score \n",
    "knn=KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(x_train.reshape(len(x_train),-1),y_train)\n",
    "y_pred_knn_A=knn.predict(x_test.reshape(len(x_test),-1))\n",
    "print(confusion_matrix(y_test,y_pred_knn_A))\n",
    "print(classification_report(y_test,y_pred_knn_A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f913f63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train and evaluate using random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf=RandomForestClassifier(n_estimators=100)\n",
    "rf.fit(x_train.reshape(len(x_train),-1),y_train)\n",
    "y_pred_rf_A=rf.predict(x_test.reshape(len(x_test),-1))\n",
    "print(confusion_matrix(y_test,y_pred_rf_A))\n",
    "print(classification_report(y_test,y_pred_rf_A))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f7f3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train and evaluate using SVM\n",
    "from sklearn.svm import SVC\n",
    "svm=SVC()\n",
    "svm.fit(x_train.reshape(len(x_train),-1),y_train)\n",
    "y_pred_svm_A=svm.predict(x_test.reshape(len(x_test),-1))\n",
    "print(confusion_matrix(y_test,y_pred_svm_A))\n",
    "print(classification_report(y_test,y_pred_svm_A))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce105c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME=f'defect-vs-nodefect-prediction-{int(time.time())}'\n",
    "tensorboard=TensorBoard(log_dir=f'logs\\\\{NAME}\\\\')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e2de5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train deep learning model\n",
    "#Deep Learning\n",
    "model_augmented= Sequential()\n",
    "model_augmented.add(Conv2D(64,(3,3), activation='relu', input_shape=x.shape[1:]))\n",
    "model_augmented.add(MaxPooling2D((2,2)))\n",
    "          \n",
    "model_augmented.add(Conv2D(64,(3,3), activation='relu'))\n",
    "model_augmented.add(MaxPooling2D((2,2)))\n",
    "\n",
    "model_augmented.add(Flatten())\n",
    "model_augmented.add(Dense(128, activation='relu'))\n",
    "model_augmented.add(Dense(1,activation='sigmoid')) #1 softmax\n",
    "model_augmented.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# model_augmented.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380b37ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_augmented.fit(x_train,y_train, epochs=37, batch_size=5, callbacks=[tensorboard])\n",
    "model_augmented.evaluate(x_test,y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bd632f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make predictions\n",
    "i=0\n",
    "data_DL_A=[]\n",
    "while i<len(y_test):\n",
    "    plt.imshow(x_test[i])\n",
    "    plt.show()\n",
    "\n",
    "    y_pred_DL=model_augmented.predict(x_test[i,:].reshape(1, 100, 100, 3))\n",
    "    print(y_pred_DL)\n",
    "    y_pred_DL=y_pred_DL>0.725\n",
    "\n",
    "    y_pred_DL= (y_pred_DL)\n",
    "\n",
    "    if(y_pred_DL== False):\n",
    "        pred='not_defective'\n",
    "    else:\n",
    "        pred='defective'\n",
    "    print(f\"The prediction was: {pred}\")\n",
    "    print(f\"The actual label was: {y_pred_DL}\")\n",
    "    if(y_test[i]==0): #good == 0  \n",
    "        print(f\"The actual label is: not defective\")\n",
    "    else: #bad == 1 \n",
    "        print(f\"The actual label is: defective\")\n",
    "    data_DL_A.append(int(y_pred_DL))\n",
    "    \n",
    "    i=i+1\n",
    "y_DL_A=[]\n",
    "for n in range(len(y_test)):\n",
    "    y_DL_A.append(n)\n",
    "plt.scatter(y_DL_A,data_DL_A)\n",
    "plt.axhline(y=0.725)\n",
    "\n",
    "plt.show\n",
    "\n",
    "\n",
    "#confusion matrix\n",
    "cm = confusion_matrix(y_test, (data_DL_A))\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24624a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate KNN\n",
    "model_evaluation(y_test, y_pred_knn_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2244e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate random forest\n",
    "model_evaluation(y_test, y_pred_rf_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9768a826",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evualate SVM\n",
    "model_evaluation(y_test, y_pred_svm_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d48ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate deep learning\n",
    "model_evaluation(y_test, data_DL_A)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
